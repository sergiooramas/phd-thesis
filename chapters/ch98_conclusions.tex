%!TEX root = ../thesis_a4.tex
\addtocontents{toc}{\protect\addvspace{2.25em plus 1pt}}
\bookmarksetup{startatroot}

\chapter{Summary and future perspectives}
\label{sec:conclusion}

\section{Introduction}

When the work for this thesis started, there was almost no published literature related with the extraction of high level semantic representations from unstructured music-related texts. Nevertheless, in the context of MIR a growing number of research works had been published exploiting either user generated texts \citep{Celma2006,lamere2008social,Whitman2002,Knees2013} or knowledge bases \citep{sordo1788,Celma:ISWC06,dbrec1,Ostuni2013}. Initial attempts to apply knowledge extraction techniques to the music domain \citep{Tata2010,Knees2011,Sordo2012}, showed the epistemic potential of text for music applications. In this thesis we have followed these ideas, deepening in the linguistic processing applied to extract the information, and proposing new approaches that exploit the extracted information in MIR tasks such as music recommendation and classification. In addition, we have combined extracted semantic information with content from other data modalities such as audio and images using deep neural networks. New data representations learned from the different data modalities and their combination have shown to outperform traditional handcrafted audio features and single modality approaches.

We started this thesis motivating and framing the work carried out with an introduction to knowledge extraction and representation learning in the context of Music Information Retrieval (MIR). In addition, we introduced the music recommendation and classification tasks (Chapter~\ref{sec:intro}). We continued by illustrating some background concepts related to Natural Language Processing (NLP), and summarizing the existing literature on text-based, knowledge-based, and deep learning approaches for Recommender Systems and MIR. Then, we described a framework for entity linking and the creation of a large corpus of annotated musical entities (Chapter~\ref{sec:linking}). Next, we proposed a method for extracting semantic relations between musical entities present in unstructured texts, and we evaluated the suitability of extracted knowledge to provide explanations for music recommendations (Chapter~\ref{sec:kb}). Two use cases on the applications of knowledge extraction for musicological studies were described next (Chapter~\ref{sec:musicology}). Then, we presented an approach for the semantic enrichment of musical texts via entity linking, which was applied to artist similarity and music genre classification (Chapter~\ref{sec:similarity}). Next, a similar idea was further developed and combined with user feedback data in the context of a hybrid music recommendation approach (Chapter~\ref{sec:graph-rec}). Finally, we described an approach to learn novel data representations from multimodal content using deep neural networks. This approach was then applied to the problems of cold-start music recommendation (Chapter~\ref{sec:cold-rec}), and multi-label music genre classification (Chapter~\ref{sec:multi-class}).

In each chapter, we provided a summary of the conclusions and relevant results of the corresponding work. In what follows, we enumerate the main contribution of this thesis. Finally, we end this dissertation with a discussion about future research directions.

\section{Summary of contributions}
\label{sec:conclusion:summary}

In this thesis, we have focused on the problem of recommending and classifying musical items in large music collections applying two different approaches: (i) an approach based on the extraction of structured knowledge from unstructured texts and its further enrichment using semantic information coming from online knowledge repositories, (ii) an approach based on representation learning from multimodal data using deep learning architectures. We now present a summary of the main contributions of this thesis.

\subsection{Scientific contributions}

\begin{enumerate}

\item 
A comprehensive review of current approaches in Natural Language Processing, Recommender Systems, and Music Information Retrieval, with a special focus on entity linking, knowledge base creation, relation extraction, artist similarity, music classification, and music recommendation (Chapter~\ref{sec:SOA}).

%\item 
%A system that integrates different entity linking tools, providing high confident entity disambiguations. The system is further leveraged for the creation of a novel benchmarking dataset of annotated musical entities, which are in turn linked to DBpedia and MusicBrainz. From this corpus, a gold standard dataset of manually annotated entities is also created.

\item 
An approach for the automatic creation of music knowledge bases from unstructured texts, which encodes semantic relations among musical entities, leveraging syntactic and semantic information (Chapter~\ref{sec:kb}). % Our method relies on the syntactic structure of sentences and the use and adaptation of music-specific heuristics for both \textsc{EL} and \textsc{RE}. %In addition, we include modules for semantic clustering and pattern scoring, aimed at the efficient removal of noisy relations. 
The approach has the following advantages:

\begin{enumerate}
\item 
It is able to capture a highly precise and compact set of weighted triples thanks to a clustering method and a novel scoring metric. 
\item 
Given a proper text corpora, it is able to extract knowledge not present in other knowledge bases, both general and domain-specific. 
\item
The extracted knowledge base is suitable to provide explanations for music recommendations.
\end{enumerate}

\item 
An exploratory study on how knowledge extraction techniques may impact musicological studies (Chapter~\ref{sec:musicology}), which has produced the following outcomes:
\begin{enumerate}
\item 
An approach for the creation of culture-specific music knowledge bases, which combines structured information coming from different data sources and information extracted from unstructured texts. 
\item
A methodology to build knowledge graphs from unstructured texts suitable for computing artist's relevance.
\item 
A method to extract and analyze the sentiment polarity expressed in music reviews, which is used to study the evolution of music genres and affective language.
%A diachronic study of the sentiment polarity expressed in album customer reviews, which suggests that non-music related circumstances may influence the way people speak about music, and demonstrate its usefulness to analyze the evolution of music genres.
\end{enumerate}

\item 
A methodology for the semantic enrichment of unstructured text documents with information present in online knowledge repositories. Enriched text representations are further exploited in artist similarity and music classification tasks, outperforming traditional text-based approaches (Chapter~\ref{sec:similarity}).

\item
An extension of the previous contribution for the creation of knowledge graphs from tags and items descriptions leveraging semantic information. These graphs are in turn exploited together with user feedback information in a hybrid recommendation approach. An extensive evaluation shows improvements with respect to state-of-the-art collaborative filtering algorithms, in terms of prediction accuracy, novelty, and aggregated diversity (Chapter~\ref{sec:graph-rec}).%  and other content-based baselines from various points of view such as prediction accuracy and catalog coverage, promoting long tail recommendations.

\item 
An approach for providing recommendations of novel artists and songs, combining audio tracks, semantically enriched artist biographies, and user feedback information using deep neural networks (Chapter~\ref{sec:cold-rec}). The proposed approach benefits from the late fusion of data representations learned separately. %Following this approach, a recommender system is able to include songs of novel artists in its recommendations with higher accuracy 

%Results suggest that both splitting the recommendation problem between feature levels, and the late fusion of feature embeddings improve the accuracy of the recommendations, and outperforms end-to-end multimodal approaches where the different modalities are learned simultaneously.
%Moreover, deep learning architectures have demonstrated their capacity to improve upon other learning models under the music recommendation framework. 
%Results have shown that our multimodal approach achieves better results than pure text or audio approaches. 

\item 
A methodology for the classification of musical items with multiple genre labels using audio, text, semantic information, and images, where novel data representations are learned using deep neural networks and further combined in a multimodal approach. Moreover, classification accuracy and aggregated diversity are improved by applying dimensionality reduction of target labels through matrix factorization techniques (Chapter~\ref{sec:multi-class}). %Additionally, a large multimodal dataset used for evaluation is released.

\end{enumerate}

\subsection{Datasets}

Due to the fact that appropriate datasets for the evaluation of our methods have not been always available, we have dedicated an important effort in gathering and curating new datasets. These are our contributions in terms of datasets.

\begin{enumerate}

\item 
Novel dataset of $\sim$13k documents and almost 150k annotated musical entities, which are linked to DBpedia and MusicBrainz. From this corpus, a gold standard dataset of 200 documents with manually annotated entities is also created (Section~\ref{sec:linking:lastfm}).

\item
Large dataset of about 64k albums with customer reviews, acoustic features per track, metadata, and single-label genre annotations (Sections ~\ref{sec:musicology:mard} and \ref{sec:similarity:mard}).

\item
Two datasets of 188 and 2,336 artist biographies respectively, together with artist similarity ground truth data (Section ~\ref{sec:similarity:experimentalsetup}).

\item
Two datasets of tags and text descriptions about musical items, together with user feedback information on those items. A dataset of sounds with $\sim$21k items and 20k users, and a dataset of songs with $\sim$8.5k items and $\sim$5k users (Section ~\ref{sec:graph-rec:datasets}).

\item
Dataset of $\sim$24k artist biographies linked to the artists present in the Million Song Dataset (Section ~\ref{sec:cold-rec:dataset}).

\item
Large dataset of about $\sim$31k albums, with $\sim$450k customer reviews, $\sim$147k audio tracks, cover artworks, and multi-label genre annotations (Section ~\ref{sec:multi-class:mumu}).

\end{enumerate}

\subsection{Music knowledge bases}

\begin{enumerate}
\item
Music knowledge base of popular music extracted from a corpus of $\sim$32k documents with stories about songs (Section~\ref{sec:kb:exp:learnedkbs}).

\item
Music knowledge base of flamenco music, created by combining data from 7 different data sources, and enriched with information extracted from $\sim$1k artist biographies (Section~\ref{sec:musicology:flabase}).

\end{enumerate}

\subsection{Software}

\begin{enumerate}
\item
A system that integrates different entity linking tools, enriching their output and providing high confident entity disambiguations.

\item
A system to perform and evaluate deep learning experiments on classification and recommendation from different data modalities and their combination. %, and to obtain feature vectors from intermediate layers after training. 

\end{enumerate}

\subsection{Publications}
\label{sec:conclusion:publications}

The research carried out in this dissertation has been published in several peer reviewed journals and top international conferences. Parts of the research presented in Chapter~\ref{sec:linking} have been published in a conference paper \citep{Oramas2016}. The work described in Chapter~\ref{sec:kb} has been published in a conference and a journal paper \citep{Oramas2015,Oramas2016a}. The parts of the research presented in Chapter~\ref{sec:musicology} related with the creation of domain-specific knowledge bases have been published in a conference and a journal paper \citep{Oramas2015b,oramas2016knowledge}, and those related with the diachronic study of music reviews were published in another conference paper \citep{oramas2016exploring}. Similarly, the parts of the research presented in Chapter~\ref{sec:similarity} related with artist similarity have been published in a conference paper \citep{Oramas2015a}, and those related with music genre classification have been published also in \cite{oramas2016exploring}. Furthermore, the outcomes of Chapter~\ref{sec:graph-rec} have been published in a journal paper \citep{oramas2016sound}. Finally, the work described in Chapter~\ref{sec:cold-rec} has been published in a conference paper \citep{oramas2017deep}, and the outcomes of the research carried out in Chapter~\ref{sec:multi-class} have been published in another conference paper \citep{oramas2017multi}. The full list of author's publications related to the work presented in this thesis is available in Appendix A, and the full list of released datasets, knowledge bases, and software is available in Appendix B.


\section{Directions for future research}
\label{sec:conclusion:future}

In the present thesis we have tried to help machines to better understand what people say about music, and we have shown how to combine semantic knowledge, texts, user feedback, audio, and images in the context of MIR and computational musicology. This is an exploratory work that opens up a number of research possibilities for text-based and multimodal approaches in the music domain. In what follows, we enumerate a series of ideas for future work related with the different tasks addressed in this dissertation.

\paragraph{Entity linking} As observed in Chapters~\ref{sec:linking} and \ref{sec:kb}, the identification and classification of music entities in text is a problem far from being solved. Current systems make an important number of mistakes and do not operate on music specific knowledge bases. Instead, current systems use general purpose ones such as DBpedia or BabelNet. As availability of music entities in these knowledge bases is scarce, there is a need for an entity linking system able to recognize and disambiguate musical entities to a music knowledge base (e.g., MusicBrainz). We envision that splitting the problem into recognition and disambiguation may improve the precision. An entity recognizer trained with music specific corpora would benefit from the textual context of the entities to properly classify them. Then, categories identified by the recognizer would be used in the disambiguation step to improve the precision of linking. To this end, the creation of large datasets of annotated musical entities is a necessary step. %, that may be of interest of NLP researchers.

\paragraph{Construction of knowledge bases} In Chapter~\ref{sec:kb} we have explored the automatic creation of music knowledge bases using an approach based on the combination of open information extraction and entity linking. However, other approaches may be used for relation extraction. In the MusicBrainz database,  a large number of relations between entities are encoded together with information about the lexicalization of these relations. This is a highly valuable resource that can be exploited, for instance, in distant supervision approaches. Additionally, the creation of an open music knowledge base that constantly reads from the web, like the Never-Ending Language Learning system (NELL) \citep{Carlson2010a}, would create a highly valuable resource, not only for research, but also for commercial applications.

\paragraph{Other NLP techniques} In this work we have explored the application of several NLP techniques and tasks to the music domain. Nevertheless, among the tasks not explored in this thesis, we may highlight Question \& Answering, which is a challenging problem that also deals with semantic representations of text. Question \& Answering systems or chat bots may have several applications to the music domain, such as knowledge dissemination, promotion of artists, or music recommendation. Big companies are currently working on their own conversational systems. Knowledge bases have been traditionally exploited by these systems, and more recently, deep learning approaches using RNNs and memory networks have shown promising results learning directly from conversations \citep{sukhbaatar2015end}. Moreover, other deep learning techniques such as reinforcement learning, have shown the potential of combining knowledge bases and deep learning in conversational systems \citep{andreas2016learning}.

\paragraph{Musicology}
In Chapter~\ref{sec:musicology} we left some hypotheses open about the evolution of the language used in music reviews. To demonstrate any of these hypotheses is a challenging problem. In addition, a more thorough study on the evolution of music genres could be done over the compiled dataset. We have shown how knowledge extraction techniques may facilitate musicologists' work. Therefore, the creation of specific tools to process large amounts of musicological documents, either in music digital libraries or private collections, is an open research direction.

\paragraph{Deep learning for text} Word vector embeddings have been shown to be very useful in most NLP tasks, and they have been widely exploited in deep learning approaches \citep{Collobert2011}. Hence, further exploration on architectures that exploit the potential of these word representations in MIR tasks is a clear research direction. Additionally, combining lexical semantics encoded in word vectors and explicit semantics encoded in knowledge bases is another open research direction. Novel techniques, such as retrofitting \citep{faruqui2014retrofitting}, go in this direction. In addition, recent developments, such as attention-based networks \citep{lin2017structured}, could be also applied in the context of our research.

\paragraph{Multimodal deep learning}
The multimodal deep learning approach presented in this thesis, is based on the late fusion of learned data representations. We have shown how this approach outperforms simultaneous learning from text and audio. However, an intermediate way would be to learn data representations separately and try to fine-tune the whole multimodal network in the final task, becoming a fully end-to-end learning approach.

\paragraph{Music classification} In Chapter~\ref{sec:multi-class} we have shown how data representations can be learned in a multi-label genre classification task. Given the high granularity of the genre annotations, learned features encode fine-grained properties of the data. Therefore, they might be exploited in other applications via transfer learning, such as music similarity or music recommendation. 

\paragraph{Music recommendation} A neural model may be learned to embed data representations from different modalities in a new multimodal space that better optimizes their similarity. Mapping multimodal data representations in a common space may be useful to pass from one modality to another. One application of this may be, for instance, going from a text description or a photo to a set of audio tracks, giving rise to new ways for playlist generation.

\paragraph{Generative models} Another interesting line of research we envision are generative models based on multimodal data. Generation of audio from text descriptions, text descriptions from audio, or album cover artwork from album tracks are some of the possible application. Similar approaches have already been developed between texts and images. However, the generation of/from audio has received less attention.

\vspace{0.4cm}

%I hope to see in the near future more automatically created knowledge bases about music, music entity linking systems with perfect precision and recall, intelligent conversational systems for music recommendation, atonishing audio generation from text descriptions, and even personalized music creations as recommendations.

All in all, the writing of this thesis has been an exciting path through different ways of incorporating further human and machine representations of musical knowledge into computational systems.